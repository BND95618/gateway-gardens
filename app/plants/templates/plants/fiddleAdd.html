<!-- app/plants/templates/plants/fiddleAdd.html -->
{% extends "plants/master.html" %}

<!-- Required in order to load static files -->
{% load static %}

{% block title %}
  <title>Fiddle Add</title>
{% endblock title %}

{% block css %}
  <link rel="stylesheet" href="{% static 'plants/css/audio_recorder.css' %}">
{% endblock css%}

{% block header-completion %}
    <!-- complete the header from master.html -->
    <div class="w3-bar w3-green">
      <h1 class="w3-bar-item">Fiddle</h1>
    </div>
  </div>
{% endblock header-completion %}

{% block content %}
  <!-- Main content-->
  <div class="w3-container" style="margin-top:150px;">
    <form name     = "audioForm"
          id       = "id_audioForm"
          action   = "" 
          method   = "post" 
          enctype  = "multipart/form-data">
      {% csrf_token %}
      <!-- ------------------------ -->
      <!-- Audio recorder HTML here -->
      <!-- ------------------------ -->
      <h5>Audio Recording - Scientific Name</h5>   
      <hr>
      <label for="id_audio_name">Audio name:</label>
      <input type="text" id="id_audio_name" name="audio_name">
      <hr>
      <div class="wrapper">
        <!-- HTML section for graphical display -->
        <section class="main-controls">
          <canvas class="visualizer" height="80px"></canvas>
          <div id="buttons">
            <button class="record w3-button w3-round-large w3-grey">Record</button>
            <button class="stop   w3-button w3-round-large w3-grey"  >Stop</button>
          </div>
        </section>
        <!-- HTML section for sound clip player -->
        <!-- Javascript will insert sound clips here -->
        <section class="sound-clips"></section>
      </div>
  
      <hr>
      <button type="submit" class="w3-button w3-green w3-round">Submit</button>
      <button type="reset"  class="w3-button w3-gray  w3-round">Reset</button>
    </form>
  </div>
{% endblock content %}

{% block js %}
<!-- ---------------------------- -->
<!-- Audio recorder Javascript    -->
<!-- ---------------------------- -->
<script>
  // --------------------------------------------------
  // Set up basic variables for app
  // > mainSection contains thw audio visualizer & record/stop buttons
  // > soundClips contain the player for the recorded audio
  // --------------------------------------------------
  const mainSection = document.querySelector(".main-controls");
  const canvas      = document.querySelector(".visualizer");
  const record      = document.querySelector(".record");
  const stop        = document.querySelector(".stop");
  const soundClips  = document.querySelector(".sound-clips");
  // Disable stop button while not recording
  stop.disabled = true;
  // Visualiser setup - create web audio api context and canvas
  let audioCtx;
  const canvasCtx = canvas.getContext("2d");
  // -------------------------------------------------- 
  // Main block for doing the audio recording
  // -------------------------------------------------- 
  if (navigator.mediaDevices.getUserMedia) 
  {
    console.log("DEBUG: The mediaDevices.getUserMedia() method is supported.");

    const constraints = { audio: true };
    let chunks = [];

    let onSuccess = function (stream) 
    {
      const mediaRecorder = new MediaRecorder(stream);

      // start to display the audio stream (live or recorded) 
      visualize(stream);
      // -------------------------------------------------- 
      // Audio Recording action after recording started
      // -------------------------------------------------- 
      record.onclick = function () 
      {
        mediaRecorder.start();
        console.log("DEBUG: Recorder started");
        console.log("DEBUG: Media Recorder state: ", mediaRecorder.state);
        record.style.background = "red";

        stop.disabled   = false;
        record.disabled = true;
      };

      stop.onclick = function () 
      {
        mediaRecorder.stop();
        console.log("DEBUG: Recorder stopped");
        console.log("DEBUG: Media Recorder state: ", mediaRecorder.state);
        record.style.background = "";
        record.style.color = "";

        stop.disabled   = true;
        record.disabled = false;
      };
      // -------------------------------------------------- 
      // Audio Recording action after recording stopped
      // -------------------------------------------------- 
      mediaRecorder.onstop = function (e) 
      {
        console.log("DEBUG: processing audio");

        const clipContainer = document.createElement("article");
        const clipLabel     = document.createElement("p");
        const audio         = document.createElement("audio");

        clipContainer.classList.add("clip");
        audio.setAttribute("controls", "");

        clipLabel.textContent = "";

        clipContainer.appendChild(audio);
        clipContainer.appendChild(clipLabel);
        // Remove any prevously recorded soundclips in this session before adding new soundclip
        if (soundClips.hasChildNodes()) 
        {
          console.log("DEBUG: Got to previous soundClips removal");
          console.log("DEBUG: soundClips.hasChildNodes(): ", soundClips.hasChildNodes());
          soundClips.removeChild(soundClips.children[0]);
        }
        soundClips.appendChild(clipContainer);

        audio.controls = true;
        const blob = new Blob(chunks, { type: mediaRecorder.mimeType });
        chunks = [];
        const audioURL = window.URL.createObjectURL(blob);
        audio.src = audioURL;
        console.log("DEBUG: audio processing complete");
        console.log("DEBUG: audio.src: ", audio.src)
        // -------------------------------------------------- 
        // Use fetch to upload the audio to the server when the form is submitted
        // --------------------------------------------------
        id_audioForm.onsubmit = async (event) => {
          event.preventDefault();
          //
          console.log("DEBUG: Uploading audio to server - Take 1");
          const csrfToken = document.querySelector('[name=csrfmiddlewaretoken]').value;
          // Get the form plus the audio recording data entered by the user
          let formData  = new FormData(id_audioForm);
          formData.append('blob', blob, 'audio_file');
          // Send the form plus the audio recording data entered by the user
          // NOTE: The url  must be set for add versus update


          const currentURL = window.location.pathname;
          let postURL = "";
          console.log("DEBUG: currentURL:", currentURL);
          if (currentURL == '/fiddleAdd')
          {
            postURL = "{% url 'plants:fiddleAdd' %}";
            console.log("DEBUG: postURL 1 =", postURL);
          }
          else
          {
            postURL = "{% url 'plants:fiddleUpdate' %}";
            console.log("DEBUG: postURL 1 =", postURL);
          }
          

          // postURL = "{% url 'plants:fiddleAdd' %}";
          console.log("DEBUG: postURL 2 =", postURL);
          alert("DEBUG: Pause");


          // Make the POST request and return a promise
          fetch(postURL, 
          {
            method: "POST",
            headers: 
            {
                'X-CSRFToken' : csrfToken
            },
            body: formData
          })
          .then(response => response.json())
          .then(result => console.log('POST was a success: ${result}'))
          .catch(error => console.error('An error occurred: ${error}'))
          // AR: Go to plant details page for plant
          let returnURL = "{% url 'plants:plants_summary' %}";
          window.location.href = returnURL;
        };
      };
      // --------------------------------------------------
      // As recording progresses, collect the audio data
      // --------------------------------------------------
      mediaRecorder.ondataavailable = function (e) 
      {
        chunks.push(e.data);
        console.log("DEBUG: audio chunk processed");
      };
    };

    let onError = function (err) 
    {
      console.log("The following error occured: " + err);
    };

    navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);
  } 
  else 
  {
    console.log("MediaDevices.getUserMedia() not supported on your browser!");
  }
  // --------------------------------------------------  
  // Display the audio stream (live or recorded)
  // -------------------------------------------------- 
  function visualize(stream) 
  {
    if (!audioCtx) 
    {
      audioCtx = new AudioContext();
    }
    const source = audioCtx.createMediaStreamSource(stream);
    const bufferLength = 2048;
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = bufferLength;
    const dataArray = new Uint8Array(bufferLength);

    source.connect(analyser);

    draw();

    function draw() 
    {
      const WIDTH = canvas.width;
      const HEIGHT = canvas.height;

      requestAnimationFrame(draw);

      analyser.getByteTimeDomainData(dataArray);

      canvasCtx.fillStyle = "rgb(200, 200, 200)";
      canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

      canvasCtx.lineWidth = 2;
      canvasCtx.strokeStyle = "rgb(0, 0, 0)";

      canvasCtx.beginPath();

      let sliceWidth = (WIDTH * 1.0) / bufferLength;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) 
      {
        let v = dataArray[i] / 128.0;
        let y = (v * HEIGHT) / 2;
        if (i === 0) 
        {
          canvasCtx.moveTo(x, y);
        } 
        else 
        {
          canvasCtx.lineTo(x, y);
        }
        x += sliceWidth;
      }

      canvasCtx.lineTo(canvas.width, canvas.height / 2);
      canvasCtx.stroke();
    }
  }
  // --------------------------------------------------
  window.onresize = function () 
  {
    canvas.width = mainSection.offsetWidth;
  };

  window.onresize();

  </script>
<!-- ---------------------------- -->
{% endblock js %}